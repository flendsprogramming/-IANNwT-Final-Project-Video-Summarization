# IANNwT-Final-Project-Video-Summarization

Everyday, people watch tons of videos to get facts and quick information, most times listening through long videos just to get a scope of what is being talked about. This VideoSummarizer project aims at providing a qualitative tool that saves a ton of time for people who want a quick summary of what a speech-talk centric video is all about without wanting to watch through every minutes of it.

To accomplish this, a pipeline of video - speech - text is implemented, using wav2vec2 pretrained model for speech-to-text stage. For the summarisation stage, a sequence to sequence deep learning model with attention mechanism is implemented in combo with the Global Vectors for Word Representation.
